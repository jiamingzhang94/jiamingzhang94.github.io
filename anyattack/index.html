<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Anyattack: Towards large-scale self-supervised adversarial attacks on vision-language models">
  <meta name="keywords" content="Computer Vision, Deep Learning, Vision-Language Models, Adversarial Attack">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Anyattack: Towards large-scale self-supervised adversarial attacks on vision-language models</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Anyattack: Towards Large-scale Self-supervised Adversarial Attacks on Vision-language Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="#">Jiaming Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Junhong Ye</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="#">Xingjun Ma</a><sup>3</sup>,</span>
            <span class="author-block">
              <a href="#">Yige Li</a><sup>4</sup>,</span>
            <span class="author-block">
              <a href="#">Yunfan Yang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="#">Jitao Sang</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="#">Dit-Yan Yeung</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Hong Kong University of Science and Technology</span><br>
            <span class="author-block"><sup>2</sup>Beijing Jiaotong University</span><br>
            <span class="author-block"><sup>3</sup>Fudan University</span><br>
            <span class="author-block"><sup>4</sup>Singapore Management University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- arXiv Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.05346"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/jiamingzhang94/AnyAttack"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>
              <!-- Paper Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2410.05346"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Model Link. -->
              <span class="link-block">
                <a href="https://gohkust-my.sharepoint.com/:u:/g/personal/jmzhang_ust_hk/EdoO5KyVBH1FhPVr1kSYWh0B61oR9MYN9_EYmrCFBKnLsQ?e=IfkDmh"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-cube"></i>
                  </span>
                  <span>Model</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Abstract Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <!-- TL;DR Section -->
        <div class="box has-background-light">
          <h3 class="title is-4 has-text-centered">TL;DR</h3>
          <p class="has-text-centered">
            We developed <strong>AnyAttack</strong>, a framework that can turn ordinary images into targeted adversarial examples that fool Vision-Language Models. By pre-training on 400M images, our method can make a benign image (like a dog) trick VLMs into generating any specified output (like "this is violent content"), working across both open-source and commercial models.
          </p>
        </div>

        <h2 class="title is-3 has-text-centered">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Vision-Language Models (VLMs) have revolutionized multimodal AI applications, yet their vulnerability to adversarial manipulation presents significant security challenges. Traditional targeted attacks require predefined labels, severely limiting their scalability and real-world impact.
          </p>
          <p>
            We introduce <strong>AnyAttack</strong>, a novel self-supervised framework that achieves unprecedented attack flexibility through large-scale foundation model training. By pre-training an adversarial noise generator on the LAION-400M dataset without label supervision, our approach enables transforming <strong>any</strong> benign image into an attack vector that can target <strong>any</strong> desired output across different VLM architecture.
          </p>
          <p>
            Our comprehensive evaluation demonstrates AnyAttack's effectiveness across five open-source VLMs (CLIP, BLIP, BLIP2, InstructBLIP, MiniGPT-4) on diverse multimodal tasks including retrieval, classification, and image captioning. Most notably, AnyAttack successfully transfers to commercial systems (Google Gemini, Claude Sonnet, Microsoft Copilot, OpenAI GPT), revealing systemic vulnerabilities in the VLM ecosystem.
          </p>
          <p>
            This work establishes the first foundation model for adversarial attacks, fundamentally reshaping the threat landscape and highlighting the urgent need for robust defense mechanisms against this new class of scalable, transferable attacks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Framework Overview Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Framework Overview</h2>

        <!-- Framework Figure -->
        <figure class="image mb-6">
          <img src="./static/images/framework.png" alt="AnyAttack Framework Overview">
          <figcaption class="has-text-centered mt-2">
            Figure 1: Overview of the AnyAttack framework, illustrating both the self-supervised adversarial noise pre-training phase (top) and the self-supervised adversarial noise fine-tuning phase (bottom).
          </figcaption>
        </figure>

        <div class="content has-text-justified">
          <p>
            Our proposed framework, <strong>AnyAttack</strong>, introduces a novel two-phase approach to generating targeted adversarial examples without label supervision:
          </p>

          <h3 class="title is-4 mt-5">Self-Supervised Adversarial Noise Pre-Training</h3>
          <p>
            In the pre-training phase, we leverage the large-scale LAION-400M dataset (ùíü<sub>p</sub>) to develop a universal understanding of adversarial patterns. We train a decoder network <em>F</em> to produce adversarial noise Œ¥ while using a frozen encoder <em>E</em> as the surrogate model:
          </p>
          <ol>
            <li>Given a batch of images <em>x</em>, we extract their embeddings using the frozen image encoder <em>E</em></li>
            <li>These normalized embeddings <strong>z</strong> are fed into the decoder <em>F</em>, which generates adversarial noise Œ¥</li>
            <li>To enhance generalization and computational efficiency, we introduce a <em>K</em>-augmentation strategy that creates multiple shuffled versions of the original images within each mini-batch</li>
            <li>The adversarial noise is added to the shuffled original images to produce the adversarial examples</li>
          </ol>

          <h3 class="title is-4 mt-5">Self-Supervised Adversarial Noise Fine-Tuning</h3>
          <p>
            In the fine-tuning phase, we adapt the pre-trained decoder <em>F</em> to specific downstream tasks and datasets (ùíü<sub>f</sub>):
          </p>
          <ol>
            <li>We use an unrelated random image <em>x<sub>r</sub></em> from an external dataset (ùíü<sub>e</sub>) as the clean image</li>
            <li>The pre-trained decoder generates adversarial noise Œ¥ specific to the target task</li>
            <li>By adding this noise to the clean image (<em>x<sub>r</sub> + Œ¥</em>), we create adversarial examples that can effectively manipulate target VLMs</li>
          </ol>

          <p class="mt-4">
            This two-phase approach enables AnyAttack to achieve unprecedented flexibility - any benign image can be transformed into an adversarial example capable of inducing any desired output from target VLMs. By pre-training on massive-scale data, our method develops transferable adversarial capabilities that generalize across models and tasks.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Framework Overview Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method Overview</h2>
        <div class="content has-text-justified">
          <img src="./static/images/framework.png" alt="Framework Overview"/>
          <p>
            [Brief description of your method and its key components. The figure above illustrates the overall architecture of our proposed approach.]
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Results Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Results</h2>
        
        <!-- Results Carousel -->
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <img src="./static/images/result1.png" alt="Result 1"/>
            <h3 class="subtitle has-text-centered">
              Result Description 1
            </h3>
          </div>
          <div class="item">
            <img src="./static/images/result2.png" alt="Result 2"/>
            <h3 class="subtitle has-text-centered">
              Result Description 2
            </h3>
          </div>
          <div class="item">
            <img src="./static/images/result3.png" alt="Result 3"/>
            <h3 class="subtitle has-text-centered">
              Result Description 3
            </h3>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- BibTeX Section -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{author2024title,
    title={Your Paper Title},
    author={Author, First and Author, Second and Author, Third},
    journal={arXiv preprint arXiv:XXXX.XXXXX},
    year={2024}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        Website template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>
      </p>
    </div>
  </div>
</footer>

</body>
</html>
